import os
import datetime
import json
import glob
from module.tool import Tool
from module.llm_agent import LLM_Agent
import yaml
import re
from dotenv import load_dotenv
from rich.progress import track
from rich.console import Console

console = Console()

def main():

    load_dotenv()

    # config.yaml ë¨¼ì € ì½ê¸°
    with open("config.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # providerì— ë”°ë¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° (.env ìš°ì„ ìˆœìœ„)
    provider = config['llm']['provider']

    if provider == 'openai':
        api_key = os.getenv('OPENAI_API_KEY')
    elif provider == 'genai':
        api_key = os.getenv('GOOGLE_API_KEY')
    else:  # ollama
        api_key = None  # ollamaëŠ” API í‚¤ ë¶ˆí•„ìš”

    llm = LLM_Agent(config['llm']['model_name'], provider, api_key)
    tool = Tool(text_output=config['folders']['text_output'],
                source_file=config['folders']['source_file'],
                result_folder=config['folders']['result_folder'],
                urls=config['urls'],
                chunk_size=config['split_text']['chunk_size'],
                overlap=config['split_text']['overlap'],
                whisper_model=config['whisper']['model'],
                audio_extensions=config['audio']['extensions'],
                max_length=config.get('max_length', 50)
            )
    tool.download_youtube_audio()
    tool.transcribe_audio()
    json_file = glob.glob(os.path.join(config['folders']['text_output'], "*.json"))

    try:
          for json_path in track(json_file, description="ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
            if not json_path:
                console.print("No json files found.")
            else:
                with open(json_path, "r", encoding="utf-8") as f:
                    json_content = json.load(f)

                json_filename = os.path.basename(json_path)
                result_json_path = os.path.join(config['folders']['result_folder'], json_filename)

                # ê°™ì€ ì´ë¦„ì˜ JSON íŒŒì¼ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                if os.path.exists(result_json_path):
                    console.print(f"ì´ë¯¸ ì¡´ì¬í•¨: {json_filename} (ê±´ë„ˆë›°ê¸°)")
                    continue  # ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°
                text_chunks = tool.split_text_with_overlap(json_content['text'])
                for i, chunk in enumerate(track(text_chunks, description="ğŸ“ ì²­í¬ ì²˜ë¦¬ ì¤‘...")):
                    # ì²­í¬ë³„ íŒŒì¼ëª… ìƒì„±
                    base_filename = tool.safe_filename(os.path.splitext(os.path.basename(json_path))[0])
                    chunk_filename = f"{base_filename}_chunk_{i+1:03d}.json"
                    chunk_path = os.path.join(config['folders']['result_folder'], chunk_filename)

                    # ì´ë¯¸ ì²˜ë¦¬ëœ ì²­í¬ëŠ” ê±´ë„ˆë›°ê¸°
                    if os.path.exists(chunk_path):
                        console.print(f"ì´ë¯¸ ì¡´ì¬í•¨: {chunk_filename} (ê±´ë„ˆë›°ê¸°)")
                        continue
                    ìš©ì–´ë¶„ì„_response = llm.generate_response(config['prompts']['ìš©ì–´ë¶„ì„_ì—ì´ì „íŠ¸'], str(f'ì›ë³¸ë°ì´í„°: {chunk}'))
                    console.print(f"ìš©ì–´ë¶„ì„ ê²°ê³¼: {ìš©ì–´ë¶„ì„_response}")
                    ê°œë…ë¶„ì„_response = llm.generate_response(config['prompts']['ê°œë…ë¶„ì„_ì—ì´ì „íŠ¸'], str(f'ì›ë³¸ë°ì´í„°: {chunk}'), data=f'ì˜¤í‘œê¸° ìˆ˜ì •ìš©ì–´ : {ìš©ì–´ë¶„ì„_response}')
                    console.print(f"ê°œë…ë¶„ì„ ê²°ê³¼: {ê°œë…ë¶„ì„_response}")
                    ë¬¸ì œì¶œì œ_response = llm.generate_response(config['prompts']['ë¬¸ì œì¶œì œ_ì—ì´ì „íŠ¸'], str(f'ì›ë³¸ë°ì´í„°: {chunk}'), data=f'ìƒì„±í•´ì•¼í•  ê°œë… ë°ì´í„° : {ê°œë…ë¶„ì„_response}')
                    console.print(f"ë¬¸ì œì¶œì œ ê²°ê³¼: {ë¬¸ì œì¶œì œ_response}")

                    # ê° ì²­í¬ë³„ ê²°ê³¼ ì €ì¥
                    chunk_questions = []
                    try:
                        if isinstance(ë¬¸ì œì¶œì œ_response, str):
                            json_match = re.search(r'\{.*\}', ë¬¸ì œì¶œì œ_response, re.DOTALL)
                            if json_match:
                                json_str = json_match.group()
                                parsed_response = json.loads(json_str)
                                chunk_questions.extend(parsed_response['questions'])
                            else:
                                console.print("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except (json.JSONDecodeError, KeyError, TypeError) as e:
                        console.print(f"ë¬¸ì œ ìƒì„± ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")

                    # ì²­í¬ë³„ ê²°ê³¼ íŒŒì¼ ì €ì¥
                    chunk_result = {
                        "chunk_info": {
                            "original_file": json_content['file_name'],
                            "chunk_number": i + 1,
                            "total_chunks": len(text_chunks),
                            "processed_time": datetime.datetime.now().isoformat()
                        },
                        "term_analysis": ìš©ì–´ë¶„ì„_response,
                        "concept_analysis": ê°œë…ë¶„ì„_response,
                        "questions": chunk_questions
                    }

                    with open(chunk_path, "w", encoding="utf-8") as f:
                        json.dump(chunk_result, f, ensure_ascii=False, indent=4)

                    console.print(f"ì²­í¬ {i+1} ì²˜ë¦¬ ì™„ë£Œ: {chunk_filename}")

                console.print(f"ëª¨ë“  ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {base_filename}")
    except Exception as e:
        console.print(f"Error: {e}")

if __name__ == "__main__":
    main()